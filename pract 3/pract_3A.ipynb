{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **SHETH L.U.J. & SIR M.V. COLLEGE**\n",
        "\n",
        "**Rajanish bhardwaj | T073**\n",
        "###Practical No. 3\n",
        "**Aim:** Feature Scaling and Dummification\n",
        "* Apply feature-scaling techniques like standardization and normalization to numerical features.\n",
        "* Perform feature dummification to convert categorical variables into numerical\n",
        "representations.\n",
        "\n",
        "### **Part 1: Handling Numerical Data**\n",
        "\n",
        "**1: Import Libraries and Load Data**"
      ],
      "metadata": {
        "id": "ZbB96mVyNfcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('heart.csv')\n",
        "print(\"Original Data Head:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLN3jAA5NlsC",
        "outputId": "1558258e-f94f-425e-b1e4-4e274275a8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Head:\n",
            "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "0  52.0  1.0  0.0     125.0  212.0  0.0      1.0    168.0    0.0      1.0   \n",
            "1  53.0  1.0  0.0     140.0  203.0  1.0      0.0    155.0    1.0      3.1   \n",
            "2  70.0  1.0  0.0     145.0  174.0  0.0      1.0    125.0    1.0      2.6   \n",
            "3  61.0  1.0  0.0     148.0  203.0  0.0      1.0    161.0    0.0      0.0   \n",
            "4  62.0  0.0  0.0     138.0  294.0  1.0      1.0    106.0    0.0      1.9   \n",
            "\n",
            "   slope   ca  thal  target  \n",
            "0    2.0  2.0   3.0     0.0  \n",
            "1    0.0  0.0   3.0     0.0  \n",
            "2    NaN  0.0   3.0     0.0  \n",
            "3    2.0  1.0   3.0     0.0  \n",
            "4    1.0  3.0   2.0     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Rescaling a Feature (MinMax Scaling)"
      ],
      "metadata": {
        "id": "OLeG8c9rN_b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will rescale 'age' to be between 0 and 1\n",
        "feature_age = df[['age']].values\n",
        "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
        "scaled_age = minmax_scaler.fit_transform(feature_age)\n",
        "\n",
        "print(\"Scaled Age (First 5 values):\")\n",
        "print(scaled_age[:5].flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N40QAknODB4",
        "outputId": "d824c9cf-62ec-4868-8497-cecb2e7b2fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Age (First 5 values):\n",
            "[0.47916667 0.5        0.85416667 0.66666667 0.6875    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Standardizing a Feature (Z-Score & Robust)"
      ],
      "metadata": {
        "id": "vHlMCAGMOJhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "# Step 1: Extract feature\n",
        "feature_chol = df[['chol']].values\n",
        "\n",
        "# Step 2: Impute missing values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "chol_imputed = imputer.fit_transform(feature_chol)\n",
        "\n",
        "# Step 3: Standardize (Mean = 0, Std = 1)\n",
        "scaler = StandardScaler()\n",
        "standardized_chol = scaler.fit_transform(chol_imputed)\n",
        "\n",
        "print(\"Standardized Cholesterol (Mean and Std):\")\n",
        "print(f\"Mean: {standardized_chol.mean():.6f}\")\n",
        "print(f\"Std:  {standardized_chol.std():.6f}\")\n",
        "\n",
        "# Step 4: Robust Scaling (Less sensitive to outliers)\n",
        "robust_scaler = RobustScaler()\n",
        "robust_chol = robust_scaler.fit_transform(chol_imputed)\n",
        "\n",
        "print(\"\\nRobust Scaled Cholesterol (First 5):\")\n",
        "print(robust_chol[:5].flatten())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1rX0EkBOKVY",
        "outputId": "d3baeb15-5c39-4be8-badd-bf6e73401c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized Cholesterol (Mean and Std):\n",
            "Mean: -0.000000\n",
            "Std:  1.000000\n",
            "\n",
            "Robust Scaled Cholesterol (First 5):\n",
            "[-0.5        -0.64516129 -1.11290323 -0.64516129  0.82258065]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: Normalizing Observations"
      ],
      "metadata": {
        "id": "eeQRoRBnPRZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import numpy as np\n",
        "\n",
        "# Extract age and chol\n",
        "features_norm = df[['age', 'chol']].values\n",
        "\n",
        "# Step 1: Impute missing values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "features_imputed = imputer.fit_transform(features_norm)\n",
        "\n",
        "# Step 2: Normalize using L2 norm\n",
        "normalizer = Normalizer(norm=\"l2\")\n",
        "normalized_features = normalizer.transform(features_imputed)\n",
        "\n",
        "print(\"Normalized Age & Chol (First 5 rows):\")\n",
        "print(normalized_features[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghy0LqC_PUYV",
        "outputId": "4ca6daa3-bbb5-4eaa-df88-b214e149c941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Age & Chol (First 5 rows):\n",
            "[[0.23822153 0.97121084]\n",
            " [0.25261592 0.96756664]\n",
            " [0.37322851 0.92773944]\n",
            " [0.28778067 0.95769634]\n",
            " [0.20634593 0.9784791 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Grouping Observations Using Clustering"
      ],
      "metadata": {
        "id": "1eYTWuVnPjXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group patients into 3 clusters based on 'age' and 'chol'\n",
        "# --- 2) Impute missing values in age and chol ---\n",
        "features_cluster = df[['age', 'chol']].values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "features_imputed = imputer.fit_transform(features_cluster)\n",
        "# --- 3) Scale the features so clusters aren't biased by magnitude ---\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_imputed)\n",
        "\n",
        "# --- 4) Run KMeans ---\n",
        "clusterer = KMeans(n_clusters=3, random_state=0)\n",
        "labels = clusterer.fit_predict(features_scaled)\n",
        "# attach cluster labels to dataframe\n",
        "df['cluster_group'] = labels\n",
        "\n",
        "# --- 5) Inspect results ---\n",
        "print(\"Clustered Groups (First 5 rows):\")\n",
        "print(df[['age', 'chol', 'cluster_group']].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bsTX13rP1GY",
        "outputId": "6f20d7f1-f944-48d6-8a83-87353a76068e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustered Groups (First 5 rows):\n",
            "    age   chol  cluster_group\n",
            "0  52.0  212.0              1\n",
            "1  53.0  203.0              1\n",
            "2  70.0  174.0              1\n",
            "3  61.0  203.0              1\n",
            "4  62.0  294.0              2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6: Deleteing Observations with Missing Values"
      ],
      "metadata": {
        "id": "iWNZf3ggP-NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna()\n",
        "\n",
        "print(df_clean.head())\n",
        "print(\"Rows before:\", len(df))\n",
        "print(\"Rows after dropna:\", len(df_clean))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxqaotU0Q61T",
        "outputId": "8d483cfe-d21c-41ed-88b9-4743c0956765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "0  52.0  1.0  0.0     125.0  212.0  0.0      1.0    168.0    0.0      1.0   \n",
            "1  53.0  1.0  0.0     140.0  203.0  1.0      0.0    155.0    1.0      3.1   \n",
            "3  61.0  1.0  0.0     148.0  203.0  0.0      1.0    161.0    0.0      0.0   \n",
            "4  62.0  0.0  0.0     138.0  294.0  1.0      1.0    106.0    0.0      1.9   \n",
            "6  58.0  1.0  0.0     114.0  318.0  0.0      2.0    140.0    0.0      4.4   \n",
            "\n",
            "   slope   ca  thal  target  cluster_group  \n",
            "0    2.0  2.0   3.0     0.0              1  \n",
            "1    0.0  0.0   3.0     0.0              1  \n",
            "3    2.0  1.0   3.0     0.0              1  \n",
            "4    1.0  3.0   2.0     0.0              2  \n",
            "6    0.0  3.0   1.0     0.0              2  \n",
            "Rows before: 1025\n",
            "Rows after dropna: 498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7: Imputing Missing Values"
      ],
      "metadata": {
        "id": "kE_eHYPJRHNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# create missing values in chol\n",
        "df_missing = df.copy()\n",
        "df_missing.loc[0:10, 'chol'] = np.nan\n",
        "\n",
        "# imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "df_imputed = df_missing.copy()\n",
        "df_imputed[['chol']] = imputer.fit_transform(df_missing[['chol']])\n",
        "\n",
        "print(\"Before imputation:\", df_missing['chol'].head(12).values)\n",
        "print(\"After imputation:\", df_imputed['chol'].head(12).values)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZd-0Q4DQGm6",
        "outputId": "bf337f72-8eb2-4ad1-bfd5-7d787adac7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before imputation: [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 341.]\n",
            "After imputation: [246.0814433 246.0814433 246.0814433 246.0814433 246.0814433 246.0814433\n",
            " 246.0814433 246.0814433 246.0814433 246.0814433 246.0814433 341.       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Handling Categorical Data & Imbalanced Classes\n",
        "\n",
        "7: Imports for Categorical Data"
      ],
      "metadata": {
        "id": "ZFU6iqLpaKKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Reload dataset to ensure clean slate for Part 2\n",
        "df = pd.read_csv('heart.csv')"
      ],
      "metadata": {
        "id": "7upKgR0vaTRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8: Encoding Nominal Categorical Features"
      ],
      "metadata": {
        "id": "-myIwuVqabxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Impute missing cp values with the most frequent (mode)\n",
        "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "cp_imputed = imputer.fit_transform(df[['cp']]).ravel()   # shape (n,)\n",
        "\n",
        "# One-hot / binarize\n",
        "one_hot = LabelBinarizer()\n",
        "cp_encoded = one_hot.fit_transform(cp_imputed)\n",
        "\n",
        "print(\"One-Hot Encoded 'cp' (First 5 rows):\")\n",
        "print(cp_encoded[:5])\n",
        "print(\"Classes:\", one_hot.classes_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR9-moJkaepm",
        "outputId": "b5f842a9-bb6c-4f9b-dafd-32319980790d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoded 'cp' (First 5 rows):\n",
            "[[1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]]\n",
            "Classes: [0. 1. 2. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9: Encoding Dictionaries of Features"
      ],
      "metadata": {
        "id": "sCtn0Sd_avtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Select two categorical columns from the heart dataset\n",
        "data_dict = df[['cp', 'thal']].to_dict(orient='records')\n",
        "\n",
        "dictvectorizer = DictVectorizer(sparse=False)\n",
        "features_dict = dictvectorizer.fit_transform(data_dict)\n",
        "\n",
        "print(\"Dictionary Vectorized Features (First row):\")\n",
        "print(features_dict[0])\n",
        "\n",
        "print(\"Feature Names:\", dictvectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U5QgtfHawdb",
        "outputId": "3b205375-ee4d-4ce0-befa-f8b544097060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary Vectorized Features (First row):\n",
            "[0. 3.]\n",
            "Feature Names: ['cp' 'thal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10: Encoding Ordinal Categorical Features (Binning)\n",
        "\n"
      ],
      "metadata": {
        "id": "9wqOrH_Vayd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Bin 'age' into groups (Young, Middle, Senior)\n",
        "df['age_group'] = pd.cut(\n",
        "    df['age'],\n",
        "    bins=[0, 30, 55, 100],\n",
        "    labels=[\"Young\", \"Middle\", \"Senior\"]\n",
        ")\n",
        "\n",
        "# Step 2: Map labels to numeric values\n",
        "scale_mapper = {\"Young\": 1, \"Middle\": 2, \"Senior\": 3}\n",
        "df['age_group_encoded'] = df['age_group'].map(scale_mapper)\n",
        "\n",
        "print(\"Binned and Encoded Age (First 5 rows):\")\n",
        "print(df[['age', 'age_group', 'age_group_encoded']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdgBL3kNa8p_",
        "outputId": "833c148b-a6e8-48ca-ffd8-926619dedcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binned and Encoded Age (First 5 rows):\n",
            "    age age_group age_group_encoded\n",
            "0  52.0    Middle                 2\n",
            "1  53.0    Middle                 2\n",
            "2  70.0    Senior                 3\n",
            "3  61.0    Senior                 3\n",
            "4  62.0    Senior                 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11: Imputing Missing Class Values (using KNN)"
      ],
      "metadata": {
        "id": "Nde3yqKObFjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Step 1 — Columns used to predict age\n",
        "features = ['chol', 'trestbps']\n",
        "\n",
        "# Step 2 — Impute missing values in predictor columns\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[features] = imputer.fit_transform(df[features])\n",
        "\n",
        "# Step 3 — Create TRAIN rows (age not missing)\n",
        "train_df = df[df['age'].notna()]\n",
        "X_train = train_df[features].values\n",
        "y_train = train_df['age'].values\n",
        "\n",
        "# Step 4 — Create TEST rows (age missing)\n",
        "test_df = df[df['age'].isna()]\n",
        "X_test = test_df[features].values   # now safe — predictors have no NaN\n",
        "\n",
        "# Step 5 — Train KNN\n",
        "knn = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Step 6 — Predict missing age\n",
        "predicted_age = knn.predict(X_test)\n",
        "\n",
        "# Step 7 — Fill back into dataframe\n",
        "df.loc[df['age'].isna(), 'age'] = predicted_age\n",
        "\n",
        "print(\"Predicted missing age values:\", predicted_age)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOkvu_FsbI1D",
        "outputId": "b6e6ed00-54d8-493f-cc00-30a39153e46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted missing age values: [71.         59.         63.         67.         56.         65.\n",
            " 43.         52.         40.         43.         56.         42.\n",
            " 38.         57.         51.         71.         52.         58.\n",
            " 70.         37.         60.         58.         54.         59.\n",
            " 55.         64.         58.         47.         60.         54.66666667\n",
            " 41.         44.         49.         48.         44.         63.\n",
            " 43.         54.         46.         63.         61.         62.\n",
            " 70.         68.         59.         50.         54.6278083  42.\n",
            " 42.         54.6278083  43.         56.         50.         64.\n",
            " 58.         47.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12: Handling Imbalanced Classes**"
      ],
      "metadata": {
        "id": "MIl5O62vDVNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Target Distribution (Original):\")\n",
        "print(df['target'].value_counts())\n",
        "\n",
        "# Identify majority and minority classes\n",
        "majority_class = 1   # 11 samples\n",
        "minority_class = 0   # 9 samples\n",
        "\n",
        "i_majority = np.where(df['target'] == majority_class)[0]\n",
        "i_minority = np.where(df['target'] == minority_class)[0]\n",
        "\n",
        "n_minority = len(i_minority)\n",
        "\n",
        "# Downsample the majority class\n",
        "downsampled_majority_indices = np.random.choice(i_majority, size=n_minority, replace=False)\n",
        "\n",
        "# Combine\n",
        "final_indices = np.hstack((i_minority, downsampled_majority_indices))\n",
        "\n",
        "df_balanced = df.iloc[final_indices]\n",
        "\n",
        "print(\"\\nBalanced Target Distribution (After Downsampling):\")\n",
        "print(df_balanced['target'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji3wKMDObvp1",
        "outputId": "84d2eaf3-c8bb-47c5-9611-4a1699d82db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Distribution (Original):\n",
            "target\n",
            "1.0    502\n",
            "0.0    471\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced Target Distribution (After Downsampling):\n",
            "target\n",
            "0.0    471\n",
            "1.0    471\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}